---
title: "FOCUS_long-term"
author: "Joseph Levine"
date created: "2021-12-21"
date edited: "2022-01-29"
output: html_document
---

```{r setup, include=FALSE}
library(stringr)
library(ggplot2)
library(ggthemes)
library(tidyverse)
library(haven)
library(devtools)
library(dplyr)
library(plyr)
library(moments)
library(magick)

# All file paths in this code refer to Joseph's directory structure. The data are taken from the OSF repository for the FOCUS data, available here: https://osf.io/794f3/
# The main impediment to getting this code to run on your own machine ill be file paths. 
# The contents of that zip file were placed in the below directory.

knitr::opts_knit$set(root.dir = "/Users/jable/Dropbox/Research/Forecasting/FOCUS/data")

#setwd("/Users/jable/Dropbox/Research/Forecasting/FOCUS/data")

options(scipen = 999)
```

## Purpose

This file will analyze data from the IARPA FOCUS project. This analysis addresses the question: how does forecasting accuracy change as the length of the forecasting period increases? 

Here are some functions I will need:

```{r import FOCUS functions}
calc.sqrt.WRPS <- function(ests.in, actual.in){
  cumulative.ests <- vector()
  cumulative.actual <- vector()
  
  for(i in 1:length(ests.in)){
    cumulative.ests[i] <- sum(ests.in[1:i])
    cumulative.actual[i] <- sum(actual.in[1:i])
  }
  
  rps <- (1/(length(ests.in)-1))*sum((cumulative.actual-cumulative.ests)^2)
  
  multipliers_df <- data.frame(
    numBins=c(2:10),
    multipliers=c(1,1.482,1.976,2.515,2.964,3.458,3.952,4.368,4.882))
  
  mult=subset(multipliers_df,numBins==length(ests.in),select=multipliers)
  
  out=round(sqrt(as.numeric(rps*mult)),3)
  
  return(out)
}

calc.sqrt.brier <- function(ests.in, actual.in){
  rps <- (1/(length(ests.in)))*sum((ests.in-actual.in)^2)
  
  multipliers_df <- data.frame(
    numBins=c(2:10),
    multipliers=c(1, 1.52, 2.22, 3.13, 4.20, 5.46, 6.88, 8.44, 10.2))
  
  mult=subset(multipliers_df, numBins==length(ests.in), select=multipliers)
  
  out=round(sqrt(as.numeric(rps*mult)),3)
  
  return(out)
}

gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
# check this more closely 

odds = function(x) {
  x / (1 - x)
}

prob = function(x) {
  x / (1 + x)
}

shannon.entropy <- function(p)
{
	if (min(p) < 0 || sum(p) <= 0)
		return(NA)
	p.norm <- p[p>0]/sum(p)
	-sum(log2(p.norm)*p.norm)
}

```


## Civilization V

The FOCUS program used six different games. The first we will analyze is Civilization V.

```{r civ5_data}
pslist <- list()

for(ps in 1:5) {
  filename <- paste0("Study 1/Civ5/Problem Set ", ps, "/ProblemSet", ps,"_ParticipantData.csv")
  psdata <- read.csv(filename)
  pslist[[ps]] <- psdata
}

all_ps = do.call(rbind, pslist) # all Civ5 problem sets in one 

# load question data (how many rounds between each question? how far in the future are we forecasting?)
# will have to manually label the years for each problem. and interpret the counterfacutal names because they are NOT well named.

forecast_period <- read.csv("Study 1/Civ5/Civ5_questions_extended.csv") # this is a hand-coded dataset which i made from the problem sets on 2021-12-22

questions_responses <- join(all_ps, forecast_period, by = c("counterfactual", "problem")) # gets the data from the forecast_period and questions files. merges question to forecast. merge on "counterfactual" (string) and "problem" (int). Should encode counterfactual... but i got the punctuation right

questions_responses$forecast_vector <- strsplit(questions_responses$forecast,split=";")
for (i in 1:nrow(questions_responses)) {
  questions_responses$forecast_vector[[i]] <- as.numeric(questions_responses$forecast_vector[[i]]) 
}

questions_responses$groundtruth_vector <- strsplit(questions_responses$ground_truth,split=";")
for (i in 1:nrow(questions_responses)) {
  questions_responses$groundtruth_vector[[i]] <- as.numeric(questions_responses$groundtruth_vector[[i]])
}


```




``` {r replicate}
keeps <- c("team", "performer", "problem_set", "problem","counterfactual","forecast_period","forecast_vector", "groundtruth_vector", "topic")
scoring <- questions_responses[keeps]


for (i in 1:length(scoring$groundtruth_vector)) {
  scoring$swrps_scores[[i]] <- calc.sqrt.WRPS(scoring$forecast_vector[[i]], scoring$groundtruth_vector[[i]]) 
  scoring$bins[[i]] <- length(scoring$forecast_vector[[i]])
}


for (i in 1:length(scoring$groundtruth_vector)) {
  scoring$brier_scores[[i]] <- calc.sqrt.brier(scoring$forecast_vector[[i]], scoring$groundtruth_vector[[i]]) 
}


# for (i in 1:length(scoring$groundtruth_vector)) {
#   scoring$ent[[i]] <- shannon.entropy(scoring$forecast_vector[[i]]) 
# }

#The scores calculated above do coordinate to what the FOCUS team included in their data files.

p <- ggplot(scoring, aes(x=forecast_period)) 

p + geom_histogram(binwidth=20) + theme_stata() + 
  xlab("Forecast Range") + ylab("Number of Forecasts")  +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Range of Questions") 
ggsave("results/civ5_periods.png", width = 10, height = 6)





```


```{r aggregate}

scoring$forecast_prob <- scoring$forecast_vector

scoring$individual <- paste(scoring$team, scoring$performer, sep = "_")

scoring <- scoring %>% select(individual, everything()) # move concatenated column to the beginning to resolve indexing

scoring <- subset(scoring, select=-c(team,performer))

for (i in 1:nrow(scoring)) {
  scoring$kurt[[i]] <- kurtosis(scoring$forecast_prob[[i]]) # a totally fake measure of overconfidence 
  scoring$skew[[i]] <- as.numeric(skewness(scoring$forecast_prob[[i]])) # a totally fake measure of overconfidence 
  scoring$range[[i]] <- diff(range(scoring$forecast_prob[[i]])) # a somewhat fake measure of overconfidence 
}

scoring$kurt <- unlist(scoring$kurt)
scoring$skew <- unlist(scoring$skew)
scoring$range <- unlist(scoring$range)
scoring$bins <- unlist(scoring$bins)
scoring$forecast_period <- unlist(scoring$forecast_period)

scoring <-  unnest_wider(scoring,forecast_vector)

colnames(scoring) <- c("individual", "problem_set", "problem", "counterfactual", "forecast_period", "bin1", "bin2", "bin3", "bin4", "bin5", "bin6", "bin7", "bin8", "bin9", "bin10", "groundtruth_prob", "topic", "swrps_scores",  "bins", "brier_scores", "forecast_prob")

scoring[, 6:15][scoring[,6:15] == 1] <- .9999 #These fuckers are too confident and infinity breaks my code

for (i in 1:10) {
  scoring[[paste0('bin',i,'odds')]] <- odds(scoring[[paste0('bin',i)]])
}

scoring$cf_question <- paste0(scoring$counterfactual,scoring$problem)
all_qs <- c(unique(scoring$cf_question))

civ5_scores <- data.frame(matrix(ncol=18,nrow=0))

colnames(civ5_scores) <- c("problem_set"    ,  "problem"    ,      "counterfactual"  , "forecast_period" , "groundtruth_prob", "topic", "bins"      ,       "cf_question"   ,   "ag_mean_1"   ,"ag_mean_2" ,       "ag_mean_3"   ,     "ag_mean_4" , "ag_mean_5"   ,"ag_mean_6" ,       "ag_mean_7"   ,     "ag_mean_8" ,   "ag_mean_9"   ,     "ag_mean_10" )

for (i in all_qs) {
  x <- subset(scoring, cf_question == i) # going question by question in this loop 
  v <- 34-(10-x$bins[[1]]) # total number of columns minus max number of bins minus actual number of bins 
  for (j in 25:v) {         # the columns with odds in them 
    u <- j-24               # starting with the first column which has odds
    x[[paste0("bin",u,"odds")]][ x[[paste0("bin",u,"odds")]] == 0] <- NA # this is a cop out because they're not really zeros, just zero odds which get ignored by the gemoetric mean function. 
    x[[paste0("ag_mean_",u)]] <- exp(mean(log(x[[paste0("bin",u,"odds")]]),na.rm=TRUE))     # calculate the geometric mean of odds for each question across competitors
  }
  v <- 35+x$bins[[1]]
  y <- x[c(2:5,16,17,19,35:v)] %>% unique()
  civ5_scores <- rbind.fill(civ5_scores,y)
}
civ5_scores <- civ5_scores  %>% mutate_at(vars(9:18), ~replace(., is.nan(.),0))

for (i in 1:10) {
  civ5_scores[[paste0('bin',i,'prob')]] <- prob(civ5_scores[[paste0('ag_mean_',i)]])
}

probs <- c('bin1prob','bin2prob','bin3prob','bin4prob','bin5prob','bin6prob','bin7prob','bin8prob','bin9prob','bin10prob')
civ5_scores$all_bins <- invisible(apply(civ5_scores[ , probs] , 1 ,paste0, collapse = ", "))


civ5_scores$all_bins <- strsplit(civ5_scores$all_bins,split=",")
for (i in 1:nrow(civ5_scores)) {
  civ5_scores$all_bins[[i]] <- as.numeric(civ5_scores$all_bins[[i]])
  civ5_scores$all_bins[[i]] <- civ5_scores$all_bins[[i]][!is.na(civ5_scores$all_bins[[i]])]
}

for (i in 1:nrow(civ5_scores)) {
  civ5_scores$swrps_scores[[i]] <- calc.sqrt.WRPS(civ5_scores$all_bins[[i]], civ5_scores$groundtruth_prob[[i]]) 
}

civ5_scores$forecast_period <- unlist(civ5_scores$forecast_period)
civ5_scores$swrps_scores <- unlist(civ5_scores$swrps_scores)

bins_range <- ggplot(civ5_scores, aes(forecast_period, bins)) # showing bins and range for each question

bins_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Number of bins") + ylim(0,10) +
  scale_y_continuous(breaks=seq(0,10,2)) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Number of Bins per Questions") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_bins_period.png", width = 10, height = 6)

lmodel <- lm(bins ~ forecast_period, data = civ5_scores)
summary(lmodel)



accuracy_range <- ggplot(civ5_scores, aes(forecast_period, swrps_scores)) # Graph of the aggregated accuracy and forecast period length

accuracy_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_score_period.png", width = 10, height = 6)


colnames(scoring)[22] <- "kurt"
colnames(scoring)[23] <- "skew"
colnames(scoring)[24] <- "range"

lmodel <- lm(swrps_scores ~ forecast_period, data = civ5_scores)
summary(lmodel)

library(moments)
kurtosis <- ggplot(scoring, aes(forecast_period, kurt))

kurtosis + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Kurtosis") + ylim(0,10) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Kurtosis and Forecast Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_kurt_period.png", width = 10, height = 6)

skewness <- ggplot(scoring, aes(forecast_period, skew))

skewness + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Skewness") + ylim(-5,5) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Skewness and Forecast Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_kurt_period.png", width = 10, height = 6)


t <- ggplot(scoring, aes(forecast_period, range))

t + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Range of forecast probabilities") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Range of Forecast Probabilities and Forecast Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_range_period.png", width = 10, height = 6)

lmodel <- lm(range ~ forecast_period, data = scoring)
summary(lmodel)


p <- ggplot(civ5_scores, aes(x=bins)) 

p + geom_histogram(binwidth=1) + theme_stata() + 
  xlab("Number of Bins") + ylab("Number of Questions")  +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Distribution of Bins") 
ggsave("results/civ5_bins.png", width = 10, height = 6)


bins_period <- ggplot(civ5_scores, aes(forecast_period, bins)) 

bins_period + geom_jitter() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Number of bins per question") + ylim(0,10) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Number of Bins") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_bins_period.png", width = 10, height = 6)


```


```{r naive calibration}

# colnames(scoring)[22] <- "kurt"
# colnames(scoring)[23] <- "skew"
# colnames(scoring)[24] <- "range"

calibration <-  unnest_wider(scoring,groundtruth_prob) # expand out the ground truths. needed for the reshaping, to line up the bins 

colnames(calibration) <- c("individual", "problem_set", "problem", "counterfactual", "forecast_period", "fcast_bin1", "fcast_bin2", "fcast_bin3", "fcast_bin4", "fcast_bin5", "fcast_bin6", "fcast_bin7", "fcast_bin8", "fcast_bin9", "fcast_bin10", "truth_bin1", "truth_bin2", "truth_bin3", "truth_bin4", "truth_bin5", "truth_bin6", "truth_bin7", "truth_bin8", "truth_bin9", "truth_bin10",  "topic", "swrps_scores",  "bins", "brier_scores", "forecast_prob", 'kurt','skew', 'range', 'bin1prob','bin2prob','bin3prob','bin4prob', 'bin5prob','bin6prob' ,'bin7prob' ,'bin8prob','bin9prob', 'bin10prob',"cf_name")
calibration$problem_id <- paste(calibration$counterfactual,calibration$problem,sep="_") # make a unique ID for each problem. problem numbers are re-used within problem sets for differetn counterfactuals, but counterfactual names are not reused. 
calibration$ID <- seq.int(nrow(calibration)) #unique problem-individual ID. Why do i need this? 
calibration <- as.data.frame(calibration)

calibration <- calibration %>% select(individual, problem_id, ID, everything()) 

calibration <- reshape(calibration, idvar="ID", direction="long", varying = list(fcast=c(8:17),truth=c(18:27)), v.names=c( "fcast", "truth")) 
calibration <- calibration[!is.na(calibration$truth),]

# Next I will find a way to randomly select rows

keeps <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")
calibration_temp <- calibration[keeps] %>% as.data.frame()


nrsim <- 10
max_prob_est <- data.frame(matrix(nrow=nrsim, ncol=4)) #stores the estimates of each run
colnames(max_prob_est) <- c("intercept", "fcast_period", "intercept_std_err", "fcast_std_err")
for (h in 1:nrsim) {
  max_calibration <- data.frame(matrix(ncol=9,nrow=0))

  colnames(max_calibration) <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")

  for (i in 1:656) {
    x <- subset(calibration_temp, ID == i) # the ID variable is question-forecaster unique
    if(x$bins[[1]]==2) {
      x <- x %>% top_n(1, fcast)
      if(x$fcast[[1]]==.5) {
        x <- x %>% slice(1)
      }
    }
    else {
      y <- sample(1:x$bins[[1]], 1)
      x <- x[ which(x$time == y),]
    }
    max_calibration <- rbind.fill(max_calibration,x)
  }
  
  lmodel <- lm(fcast ~ forecast_period, data = max_calibration)
  lmodel <- coef(summary(lmodel))
  lmodel <- as.data.frame(lmodel)
  colnames(lmodel) <- c("Estimate","std_err", "tval", "pval")
  max_prob_est$intercept[h] <- lmodel$Estimate[[1]]
  max_prob_est$fcast_period[h] <- lmodel$Estimate[[2]]
  max_prob_est$intercept_std_err[h] <- lmodel$std_err[[1]]
  max_prob_est$fcast_std_err[h] <- lmodel$std_err[[2]]
}

#calculate t values 

 max_prob_est$int_tstat <- max_prob_est$intercept/max_prob_est$intercept_std_err
 max_prob_est$per_tstat <-  max_prob_est$fcast_period/max_prob_est$fcast_std_err
 max_prob_est$int_pval <- 1-pt(max_prob_est$int_tstat,655)
 max_prob_est$per_pval <-  1-pt(max_prob_est$per_tstat,655)

mfcast_b <- mean(max_prob_est$fcast_period)
sefcast_b <- sd(max_prob_est$fcast_period)
plot(density(max_prob_est$fcast_period))
curve(dnorm(x, mfcast_b, sefcast_b), col="red", add=TRUE)
legend("topright", legend=c("true", "simulated"), 
       lty=1, col=c("red", "black"))

ggplot(max_prob_est, aes(x=fcast_period)) + theme_stata() +
  geom_histogram(aes(y = ..density..), position = "identity",
                 colour="black", fill="white", cex = 0.8) +
  geom_density(fill="grey",cex = 0.8, alpha = 0.5) +
  ylab("Density") + 
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Historgram of Coefficients (forecast_period)") 
ggsave("results/civ5_rand_prob_density.png", width = 10, height = 6)



```

```{r same but binary}

# This section does the same analysis, but also randomly draws from binary questions

nrsim <- 10
max_prob_est <- data.frame(matrix(nrow=nrsim, ncol=4)) #stores the estimates of each run
colnames(max_prob_est) <- c("intercept", "fcast_period", "intercept_std_err", "fcast_std_err")
for (h in 1:nrsim) {
  max_calibration <- data.frame(matrix(ncol=9,nrow=0))

  colnames(max_calibration) <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")

  for (i in 1:656) {
    x <- subset(calibration_temp, ID == i) # the ID variable is question-forecaster unique
      y <- sample(1:x$bins[[1]], 1)
      x <- x[ which(x$time == y),]
    max_calibration <- rbind.fill(max_calibration,x)
  }
  
  lmodel <- lm(fcast ~ forecast_period, data = max_calibration)
  lmodel <- coef(summary(lmodel))
  lmodel <- as.data.frame(lmodel)
  colnames(lmodel) <- c("Estimate","std_err", "tval", "pval")
  max_prob_est$intercept[h] <- lmodel$Estimate[[1]]
  max_prob_est$fcast_period[h] <- lmodel$Estimate[[2]]
  max_prob_est$intercept_std_err[h] <- lmodel$std_err[[1]]
  max_prob_est$fcast_std_err[h] <- lmodel$std_err[[2]]
}

#calculate t values 

 max_prob_est$int_tstat <- max_prob_est$intercept/max_prob_est$intercept_std_err
 max_prob_est$per_tstat <-  max_prob_est$fcast_period/max_prob_est$fcast_std_err
 max_prob_est$int_pval <- 1-pt(max_prob_est$int_tstat,655)
 max_prob_est$per_pval <-  1-pt(max_prob_est$per_tstat,655)

mfcast_b <- mean(max_prob_est$fcast_period)
sefcast_b <- sd(max_prob_est$fcast_period)
plot(density(max_prob_est$fcast_period))
curve(dnorm(x, mfcast_b, sefcast_b), col="red", add=TRUE)
legend("topright", legend=c("true", "simulated"), 
       lty=1, col=c("red", "black"))
```

```{r selecting maximum}
#Instead of selecting a random bin, this chunk selects the maximum bin.  

  max_calibration <- data.frame(matrix(ncol=9,nrow=0))

  colnames(max_calibration) <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")

  for (i in 1:656) {
    x <- subset(calibration_temp, ID == i) # the ID variable is question-forecaster unique
      x <- x %>% top_n(1, fcast)
      if(x$fcast[[1]]==.5) {
        x <- x %>% slice(1)
      }
    max_calibration <- rbind.fill(max_calibration,x)
  }


max_prob_range <- ggplot(max_calibration, aes(forecast_period, fcast)) # Graph of the maximum forecast and forecast period length

max_prob_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Maximum Bin Probability") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Maximum and Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_max_prob_period.png", width = 10, height = 6)

  lmodel <- lm(fcast ~ forecast_period, data = max_calibration)
  summary(lmodel)



```



```{r making gif} 
#Going to make a fun gif

nrsim <- 20
for (h in 1:nrsim) {
  max_calibration <- data.frame(matrix(ncol=9,nrow=0))

  colnames(max_calibration) <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")

  for (i in 1:656) {
    x <- subset(calibration_temp, ID == i) # the ID variable is question-forecaster unique
      y <- sample(1:x$bins[[1]], 1)
      x <- x[ which(x$time == y),]
    max_calibration <- rbind.fill(max_calibration,x)
  }
  accuracy_range <- ggplot(max_calibration, aes(forecast_period, fcast)) # Graph of the aggregated accuracy and randomly selected or maximum forecast value

  accuracy_range + geom_jitter() + theme_stata() + 
    xlab("Number of Turns in Forecast Period") + ylab("Forecasted Probability") + ylim(0,1) +
    theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
    ggtitle("Civ5 Forecast Accuracy and Randomly Selected/Maximum Forecasted Probability") +
    geom_smooth(method='lm', fill = NA) +  annotate("text", label = h, x = 400, y = 1, size = 10)
  j <- h +10
  ggsave(paste0("results/max_gif/civ5_score_max_",j,".png"), width = 10, height = 6)
}

## list file names and read in
imgs <- list.files("results/max_gif", full.names = TRUE)
img_list <- lapply(imgs, image_read)

## join the images together
img_joined <- image_join(img_list)

## animate at 2 frames per second
img_animated <- image_animate(img_joined, fps = 1)

## save to disk
image_write(image = img_animated,
            path = "results/max_gif/rand_20_runs.gif")

```




```{r making another gif} 
#Going to make a fun gif in this one, we take the larger of binary, everything else is the same (random)

nrsim <- 20
for (h in 1:nrsim) {
  max_calibration <- data.frame(matrix(ncol=9,nrow=0))

  colnames(max_calibration) <- c("individual", "problem_id", "ID", "forecast_period", "topic", "bins", "time", "fcast", "truth")

  for (i in 1:656) {
    x <- subset(calibration_temp, ID == i) # the ID variable is question-forecaster unique
    if(x$bins[[1]]==2) {
      x <- x %>% top_n(1, fcast)
      if(x$fcast[[1]]==.5) {
        x <- x %>% slice(1)
      }
    }
    else {
      y <- sample(1:x$bins[[1]], 1)
      x <- x[ which(x$time == y),]
    }
    max_calibration <- rbind.fill(max_calibration,x)
  }
  accuracy_range <- ggplot(max_calibration, aes(forecast_period, fcast)) # Graph of the aggregated accuracy and randomly selected or maximum forecast value

  accuracy_range + geom_jitter() + theme_stata() + 
    xlab("Number of Turns in Forecast Period") + ylab("Forecasted Probability") + ylim(0,1) +
    theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
    ggtitle("Civ5 Forecast Accuracy and Randomly Selected/Maximum Forecasted Probability") +
    geom_smooth(method='lm', fill = NA) +  annotate("text", label = h, x = 400, y = 1, size = 10)
  j <- h +10
  ggsave(paste0("results/max_gif_nb/civ5_score_max_",j,".png"), width = 10, height = 6)
}

## list file names and read in
imgs <- list.files("results/max_gif", full.names = TRUE)
img_list <- lapply(imgs, image_read)

## join the images together
img_joined <- image_join(img_list)

## animate at 2 frames per second
img_animated <- image_animate(img_joined, fps = 1)

## save to disk
image_write(image = img_animated,
            path = "results/max_gif/rand_20_runs.gif")

```


```{r}

confidence_range <- ggplot(max_calibration, aes(forecast_period, fcast)) # Graph of the aggregated accuracy and forecast period length

confidence_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Confidence level (max or random)") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Confidence") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_confidence_period.png", width = 10, height = 6)

scoring$forecast_period <- unlist(scoring$forecast_period)
scoring$ent <- unlist(scoring$ent)
scoring$bins <- unlist(scoring$bins)

ent_8 <- scoring[ which(scoring$bins == 8), ]

entropy_range <- ggplot(ent_8, aes(forecast_period, ent))

entropy_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Entropy") + ylim(0,3) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Entropy (Eight bins only)") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_entropy_period_8.png", width = 10, height = 6)

  lmodel <- lm(ent ~ forecast_period, data = ent_8)
  summary(lmodel)

  
  
entropy_range <- ggplot(scoring, aes(forecast_period, ent))

entropy_range + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Entropy") + ylim(0,3) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Forecast Accuracy and Entropy (all bins)") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_entropy_period_all.png", width = 10, height = 6)

  lmodel <- lm(ent ~ forecast_period, data = scoring)
  summary(lmodel)

  

entropy_bins <- ggplot(scoring, aes(bins, ent))

entropy_bins + geom_point() + theme_stata() + 
  xlab("Number of Bins") + ylab("Entropy") + ylim(0,3) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 Bins and Entropy") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_entropy_bins.png", width = 10, height = 6)
```

```{r calibration}


#detach(package:plyr)
keeps <- c("forecast_period", "cf_name", "fcast", "truth")
naive_calibration <- calibration[keeps] %>% as.data.frame() %>% drop_na(truth)  %>% mutate_at(vars(3), ~replace(., is.nan(.),NA)) # some of the NAs snuck through

naive_calibration$fcast_dec <- (ceiling(naive_calibration$fcast*10)/10) - .05 # the .05 just makes it look pretty for the graph.
naive_calibration$truth_dec <- (ceiling(naive_calibration$truth*10)/10) - .05

library(plyr)
naive_calibration$period_cent <- round_any(naive_calibration$forecast_period, 100, f = ceiling)

detach(package:plyr)
naive_calibration <- naive_calibration %>% group_by(fcast_dec,period_cent) %>% 
  summarize(truth = mean(truth, na.rm=T),
            n = n())

q <- ggplot(naive_calibration, aes(x=fcast_dec, y=truth, color = factor(period_cent), group = factor(period_cent)))

q + geom_point() + theme_stata() + 
  xlab("Predicted Frequency") + ylab("Realized Frequency") + ylim(0,1) + xlim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Civ5 Calibration",
       subtitle="By Forecast Range") +
  scale_color_manual(labels = c("\u2264 100 turns", "101 to 200 turns", "201 to 300 turns", "\u2265 300 turns"), values = c("blue", "red", "black", "green")) + theme(legend.title=element_blank()) +
  geom_path() +
  geom_abline(slope=1)
ggsave("results/civ5_calib_range.png", width = 10, height = 6)

categories <- naive_calibration %>% group_by(period_cent) %>% 
  summarize(sum = sum(n, na.rm=T)) 
# in total 3,383 forecasts. 
categories$prop <- categories$sum/3383


```


```{r by forecast topic}
#checking if it's easier to make e.g., demographic forecasts than technological forecasts
q <- ggplot(civ5_scores, aes(x=forecast_period, y=swrps_scores, color=topic))

q + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Civ5 Forecast Accuracy and Period Length",
       subtitle="By Forecast Topic") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_score_period_topic.png", width = 10, height = 6)

civ5_scores$problem_set <- as.character(civ5_scores$problem_set)

```

```{r by problem set}
# checking if some problem sets were harder than others
r <- ggplot(civ5_scores, aes(x=forecast_period, y=swrps_scores, color=factor(problem_set), group=factor(problem_set)))

r + geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Civ5 Forecast Accuracy and Period Length",
       subtitle="By Problem Set") +
  scale_color_manual(labels = c("PS1", "PS2", "PS3", "PS4", "PS5"), values = c("blue", "red", "black", "green", "purple")) + theme(legend.title=element_blank()) +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_score_period_ps.png", width = 10, height = 6)



```



## Critter World


```{r Critter_world}
pslist <- list()

for(ps in 1:2) {
  filename <- paste0("Study 1/Critter World/Problem Set ", ps, "/ProblemSet", ps,"_ParticipantData_rec.csv")
  psdata <- read.csv(filename)
  pslist[[ps]] <- psdata
}

for(ps in 1:2) {
  filename <- paste0("Study 2/Critter World/Problem Set ", ps, "/ProblemSet", ps,"_ParticipantData_rec.csv")
  psdata <- read.csv(filename)
  ps <- ps + 2
  pslist[[ps]] <- psdata
}

pslist[[5]] <- read.csv("Study 3/Critter World/CritterWorld_Study3_Participant_data_rec.csv")

all_ps_cw = do.call(rbind, pslist) 


forecast_period_cw <- read.csv("Study 1/Critter World/cw_questions_extended.csv") # this is a hand-coded dataset which i made from the problem sets on 2021-12-27. CONTAINS ALL THREE StUDIES
library(plyr)
questions_responses_cw <- join(all_ps_cw, forecast_period_cw, by = c("counterfactual", "question")) # gets the data from the forecast_period and questions files. merges question to forecast. merge on "counterfactual" (string) and "problem" (int). Should encode counterfactual... but i got the punctuation right

questions_responses_cw$forecast_vector <- strsplit(questions_responses_cw$forecast,split=";")
for (i in 1:nrow(questions_responses_cw)) {
  questions_responses_cw$forecast_vector[[i]] <- as.numeric(questions_responses_cw$forecast_vector[[i]]) 
}

questions_responses_cw$groundtruth_vector <- strsplit(questions_responses_cw$ground_truth,split=";")
for (i in 1:nrow(questions_responses_cw)) {
  questions_responses_cw$groundtruth_vector[[i]] <- as.numeric(questions_responses_cw$groundtruth_vector[[i]])
}


```


```{r aggregate}

keeps <- c("counterfactual", "question","forecast_period","forecast_vector", "groundtruth_vector")
scoring_cw <- questions_responses_cw[keeps]

scoring_cw$forecast_prob <- scoring_cw$forecast_vector

for (i in 1:length(scoring_cw$question)) {
  scoring_cw$bins[[i]] <- length(scoring_cw$forecast_vector[[i]])
}

scoring_cw <-  unnest_wider(scoring_cw,forecast_vector)

colnames(scoring_cw) <- c("counterfactual", "problem", "forecast_period", "bin1", "bin2", "bin3", "bin4", "bin5", "bin6", "bin7", "bin8", "bin9", "bin10",  "groundtruth_prob", "forecast_prob",  "bins")

scoring_cw[, 4:13][scoring_cw[,4:13] == 1] <- .9999 #These fuckers are too confident and infinity breaks my code


for (i in 1:10) {
  scoring_cw[[paste0('bin',i,'odds')]] <- odds(scoring_cw[[paste0('bin',i)]])
}

scoring_cw$cf_question <- paste0(scoring_cw$counterfactual,scoring_cw$problem)
all_qs <- c(unique(scoring_cw$cf_question))

cw_means <- data.frame(matrix(ncol=16,nrow=0))

colnames(cw_means) <- c(  "problem"    ,      "counterfactual"  , "forecast_period" , "groundtruth_prob", "bins"      ,       "cf_question"   ,   "ag_mean_1"   ,"ag_mean_2" ,       "ag_mean_3"   ,     "ag_mean_4" , "ag_mean_5"   ,"ag_mean_6" ,       "ag_mean_7"   ,     "ag_mean_8", "ag_mean_9", "ag_mean_10"   )

for (i in all_qs) {
  x <- subset(scoring_cw, cf_question == i) # going question by question in this loop 
  v <- 27-(11-x$bins[[1]]) # total number of columns minus max number of bins minus actual number of bins 
  for (j in 17:v) { # the columns with odds in them 
    u <- j-16       # starting with the first column which as odds
    x[[paste0("bin",u,"odds")]][ x[[paste0("bin",u,"odds")]] == 0] <- NA # this is a cop out because they're not really zeros, just zero odds which get ignored by the gemoetric mean function. 
    x[[paste0("ag_mean_",u)]] <- exp(mean(log(x[[paste0("bin",u,"odds")]]),na.rm=TRUE)) # This calculates the geometric mean of the odds
  }
  v <- 28+x$bins[[1]]-1 #starting at the new mean columns
  y <- x[c(1:3,14,16,27:v)] %>% group_by(counterfactual, problem)  %>% slice(1) # JABL
  cw_means <- rbind.fill(cw_means,y)
}
cw_means <- cw_means  %>% mutate_at(vars(7:16), ~replace(., is.nan(.),0))

for (i in 1:10) {
  cw_means[[paste0('bin',i,'prob')]] <- prob(cw_means[[paste0('ag_mean_',i)]])
}

probs <- c('bin1prob','bin2prob','bin3prob','bin4prob','bin5prob','bin6prob','bin7prob','bin8prob','bin9prob','bin10prob')
cw_means$all_bins <- invisible(apply(cw_means[ , probs] , 1 ,paste0, collapse = ", "))


cw_means$all_bins <- strsplit(cw_means$all_bins,split=",")
for (i in 1:nrow(cw_means)) {
  cw_means$all_bins[[i]] <- as.numeric(cw_means$all_bins[[i]])
  cw_means$all_bins[[i]] <- cw_means$all_bins[[i]][!is.na(cw_means$all_bins[[i]])]
}

for (i in 1:nrow(cw_means)) {
  cw_means$swrps_scores[[i]] <- calc.sqrt.WRPS(cw_means$all_bins[[i]], cw_means$groundtruth_prob[[i]]) 
}

cw_means$forecast_period <- unlist(cw_means$forecast_period)
cw_means$swrps_scores <- unlist(cw_means$swrps_scores)

p <- ggplot(cw_means, aes(forecast_period, swrps_scores))

p+ geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Critter World Forecast Accuracy and Period Length",
       subtitle="With Outlier") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/cw_score_period_with_outlier.png", width = 10, height = 6)

lmodel <- lm(swrps_scores ~ forecast_period, data = cw_means)
summary(lmodel)

cw_means <- cw_means[-12] # removing a single outlier (580 turns)

p <- ggplot(cw_means, aes(forecast_period, swrps_scores))

p+ geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Critter World Forecast Accuracy and Period Length",
       subtitle="Without Outlier") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/cw_score_period_without_outlier.png", width = 10, height = 6)

lmodel <- lm(swrps_scores ~ forecast_period, data = cw_means)
summary(lmodel)


```

```{r cw less than 100}
cw_means <- cw_means[cw_means$forecast_period<100,] # removing all quesitons with over 100 turns

p <- ggplot(cw_means, aes(forecast_period, swrps_scores))

p+ geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="Critter World Forecast Accuracy and Period Length",
       subtitle="Questions with range \u2264 100") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/cw_score_period_ltoet_100.png", width = 10, height = 6)

lmodel <- lm(swrps_scores ~ forecast_period, data = cw_means)
summary(lmodel)




```


## FLuTE


```{r FLuTE}

all_ps_flute <- read.csv("Study 1/Flute/Problem Set/ProblemSet_ParticipantData.csv")

forecast_period_flute <- read.csv("Study 1/Flute/flute_questions_extended.csv") # this is a hand-coded dataset which i made from the problem sets on 2021-12-22

questions_responses_flute <- join(all_ps_flute, forecast_period_flute, by = c("counterfactual", "problem")) # gets the data from the forecast_period and questions files. merges question to forecast. merge on "counterfactual" (string) and "problem" (int). Should encode counterfactual... but i got the punctuation right

questions_responses_flute$forecast_vector <- strsplit(questions_responses_flute$forecast,split=";")
for (i in 1:nrow(questions_responses_flute)) {
  questions_responses_flute$forecast_vector[[i]] <- as.numeric(questions_responses_flute$forecast_vector[[i]]) 
}

questions_responses_flute$groundtruth_vector <- strsplit(questions_responses_flute$ground_truth,split=";")
for (i in 1:nrow(questions_responses_flute)) {
  questions_responses_flute$groundtruth_vector[[i]] <- as.numeric(questions_responses_flute$groundtruth_vector[[i]])
}


```


```{r aggregate}

keeps <- c("counterfactual", "problem","forecast_period","forecast_vector", "groundtruth_vector")
scoring_flute <- questions_responses_flute[keeps]

scoring_flute$forecast_prob <- scoring_flute$forecast_vector

for (i in 1:length(scoring_flute$problem)) {
  scoring_flute$bins[[i]] <- length(scoring_flute$forecast_vector[[i]])
}

scoring_flute <-  unnest_wider(scoring_flute,forecast_vector)

colnames(scoring_flute) <- c("counterfactual", "problem", "forecast_period", "bin1", "bin2", "bin3", "bin4", "bin5",   "groundtruth_prob", "forecast_prob",  "bins")

scoring_flute[, 4:8][scoring_flute[,4:8] == 1] <- .9999 #These fuckers are too confident and infinity breaks my code


for (i in 1:5) {
  scoring_flute[[paste0('bin',i,'odds')]] <- odds(scoring_flute[[paste0('bin',i)]])
}

scoring_flute$cf_question <- paste0(scoring_flute$counterfactual,scoring_flute$problem)
all_qs <- c(unique(scoring_flute$cf_question))
#all_qs <- all_qs[-12] # removing a single outlier (580 turns)

flute_means <- data.frame(matrix(ncol=11,nrow=0))

colnames(flute_means) <- c(  "problem"    ,      "counterfactual"  , "forecast_period" , "groundtruth_prob", "bins"      ,       "cf_question"   ,   "ag_mean_1"   ,"ag_mean_2" ,       "ag_mean_3"   ,     "ag_mean_4" , "ag_mean_5")

for (i in all_qs) {
  x <- subset(scoring_flute, cf_question == i) # going question by question in this loop 
  v <- 17-(6-x$bins[[1]]) # total number of columns minus max number of bins minus actual number of bins 
  for (j in 12:v) { # the columns with odds in them 
    u <- j-11       # starting with the first column which as odds
    x[[paste0("bin",u,"odds")]][ x[[paste0("bin",u,"odds")]] == 0] <- NA # this is a cop out because they're not really zeros, just zero odds which get ignored by the gemoetric mean function. 
    x[[paste0("ag_mean_",u)]] <- exp(mean(log(x[[paste0("bin",u,"odds")]]),na.rm=TRUE)) # This calculates the geometric mean of the odds
  }
  v <- 18+x$bins[[1]]-1 #starting at the new mean columns
  y <- x[c(1:3,9,11,17:v)] %>% group_by(counterfactual, problem)  %>% slice(1) # JABL
  flute_means <- rbind.fill(flute_means,y)
}

for (i in 1:5) {
  flute_means[[paste0('bin',i,'prob')]] <- prob(flute_means[[paste0('ag_mean_',i)]])
}

probs <- c('bin1prob','bin2prob','bin3prob','bin4prob','bin5prob')
flute_means$all_bins <- invisible(apply(flute_means[ , probs] , 1 ,paste0, collapse = ", "))


flute_means$all_bins <- strsplit(flute_means$all_bins,split=",")
for (i in 1:nrow(flute_means)) {
  flute_means$all_bins[[i]] <- as.numeric(flute_means$all_bins[[i]])
  flute_means$all_bins[[i]] <- flute_means$all_bins[[i]][!is.na(flute_means$all_bins[[i]])]
}

for (i in 1:nrow(flute_means)) {
  flute_means$swrps_scores[[i]] <- calc.sqrt.WRPS(flute_means$all_bins[[i]], flute_means$groundtruth_prob[[i]]) 
}

flute_means$forecast_period <- unlist(flute_means$forecast_period)
flute_means$swrps_scores <- unlist(flute_means$swrps_scores)

p <- ggplot(flute_means, aes(forecast_period, swrps_scores))

p <- p+ geom_point() + theme_stata() + 
  xlab("Number of Turns in Forecast Period") + ylab("Mean WRPS Score") + ylim(0,2) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  labs(title="FLuTE Forecast Accuracy and Period Length") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/flute_score_period.png", width = 10, height = 6)

lmodel <- lm(swrps_scores ~ forecast_period, data = flute_means)
summary(lmodel)


```



## Pathwayz


```{r pathwayz}
all_ps_pathwayz <- read.csv("Study 3/Pathwayz/Pathwayz_Study3_Participant_data.csv")

forecast_period_pathwayz <- read.csv("Study 3/Pathwayz/pathwayz_questions_extended.csv") # Almost all questions don't have a well defined end period

questions_responses_flute <- join(all_ps_pathwayz, forecast_period_pathwayz, by = c("question")) 



```






## Stratego


```{r stratego}

pslist <- list() 

for(ps in 1:2) {
  filename <- paste0("Study 2/Stratego/Problem Set ", ps, "/ProblemSet", ps,"_ParticipantData.csv")
  psdata <- read.csv(filename)
  pslist[[ps]] <- psdata
}

pslist[[3]] <- read.csv("Study 3/Stratego/Stratego_Study3_Participant_data.csv")

all_ps_stratego = do.call(rbind, pslist) # This doesn't run because column names changed across studies. Will take ~1 hour to fix but 

forecast_period_stratego <- read.csv("") # NEED TO THINK ABOUT THIS, lots of questions with no strict resolution period.

questions_responses_stratego <- join(all_ps_stratego, forecast_period_stratego, by = c("counterfactual", "question")) # gets the data from the forecast_period and questions files. merges question to forecast. merge on "counterfactual" (string) and "problem" (int). Should encode counterfactual... but i got the punctuation right


```







``` {r unweighted}

# taking away the weights from the multipliers round 
calc.sqrt.RPS <- function(ests.in, actual.in){
  cumulative.ests <- vector()
  cumulative.actual <- vector()
  
  for(i in 1:length(ests.in)){
    cumulative.ests[i] <- sum(ests.in[1:i])
    cumulative.actual[i] <- sum(actual.in[1:i])
  }
  
  rps <- (1/(length(ests.in)-1))*sum((cumulative.actual-cumulative.ests)^2)
  
  multipliers_df <- data.frame(
    numBins=c(2:10),
    multipliers=c(1,1,1,1,1,1,1,1,1))
  
  mult=subset(multipliers_df,numBins==length(ests.in),select=multipliers)
  
  out=round(sqrt(as.numeric(rps*mult)),3)
  
  return(out)
}




# Re-running the bit where i calculate the scores
for (i in 1:nrow(civ5_scores)) {
  civ5_scores$srps_scores[[i]] <- calc.sqrt.RPS(civ5_scores$all_bins[[i]], civ5_scores$groundtruth_prob[[i]]) 
}

for (i in 1:nrow(civ5_scores)) {
  civ5_scores$swrps_scores[[i]] <- calc.sqrt.WRPS(civ5_scores$all_bins[[i]], civ5_scores$groundtruth_prob[[i]]) 
}

civ5_scores$forecast_period <- unlist(civ5_scores$forecast_period)
civ5_scores$swrps_scores <- unlist(civ5_scores$swrps_scores)
civ5_scores$srps_scores <- unlist(civ5_scores$srps_scores)

civ5_scores$score_diff <- civ5_scores$swrps_scores-civ5_scores$srps_scores

bins_weight <- ggplot(civ5_scores, aes(bins, score_diff)) 

bins_weight + geom_point() + theme_stata() + 
  xlab("Number of Bins") + ylab("WRPS minus RPS") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 difference between weighted and unweighted scores") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_bins_score_diff.png", width = 10, height = 6)



scoring$bins <- unlist(scoring$bins)
scoring$swrps_scores <- unlist(scoring$swrps_scores)
scoring$srps_scores <- unlist(scoring$srps_scores)

scoring$score_diff <- scoring$swrps_scores-scoring$srps_scores

bins_weight <- ggplot(scoring, aes(bins, score_diff)) 

bins_weight + geom_point() + theme_stata() + 
  xlab("Number of Bins") + ylab("WRPS minus RPS") + ylim(0,1) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  ggtitle("Civ5 difference between weighted and unweighted scores") +
  geom_smooth(method='lm', fill = NA) 
ggsave("results/civ5_all_score_diff.png", width = 10, height = 6)



```



```
